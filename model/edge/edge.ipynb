{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "47jNyI5yvrxu",
    "outputId": "ae07ef66-5a7f-4f03-a1c1-130e6841b104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from edsr.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chandu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "from tqdm import tqdm as tqdm\n",
    "import edsr\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yDiMgZw_eaag"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "MAX = 1\n",
    "GAUS_KERNEL = 3\n",
    "GAUS_SIGMA  = 1.2\n",
    "\n",
    "def Gaussian_Filter(kernel_size=GAUS_KERNEL, sigma=GAUS_SIGMA):\n",
    "    \n",
    "\tk = (kernel_size-1)//2 \n",
    "\tfilter = []\n",
    "\tsigma_2 = sigma**2\n",
    "\tfor i in range(kernel_size):\n",
    "\t\tfilter_row = []\n",
    "\t\tfor j in range(kernel_size):\n",
    "\t\t\tHij = np.exp(-((i+1-(k+1))**2 + (j+1-(k+1))**2)/(2*sigma_2))/(2*np.pi*sigma_2)\n",
    "\t\t\tfilter_row.append(Hij)\n",
    "\t\tfilter.append(filter_row)\n",
    "\t\n",
    "\treturn np.asarray(filter).reshape(kernel_size,kernel_size,1,1)\n",
    "\n",
    "gaussian_filter = tf.constant(Gaussian_Filter(), tf.float32) \t\t\t\t\n",
    "h_filter = tf.reshape(tf.constant([[-1,0,1],[-2,0,2],[-1,0,1]], tf.float32), [3,3,1,1])\t\n",
    "v_filter = tf.reshape(tf.constant([[1,2,1],[0,0,0],[-1,-2,-1]], tf.float32), [3,3,1,1])\t\n",
    "\n",
    "np_filter_0 = np.zeros((3,3,1,2))\n",
    "np_filter_0[1,0,0,0], np_filter_0[1,2,0,1] = 1,1 \n",
    "filter_0 = tf.constant(np_filter_0, tf.float32)\n",
    "np_filter_90 = np.zeros((3,3,1,2))\n",
    "np_filter_90[0,1,0,0], np_filter_90[2,1,0,1] = 1,1 \n",
    "filter_90 = tf.constant(np_filter_90, tf.float32)\n",
    "np_filter_45 = np.zeros((3,3,1,2))\n",
    "np_filter_45[0,2,0,0], np_filter_45[2,0,0,1] = 1,1 \n",
    "filter_45 = tf.constant(np_filter_45, tf.float32)\n",
    "np_filter_135 = np.zeros((3,3,1,2))\n",
    "np_filter_135[0,0,0,0], np_filter_135[2,2,0,1] = 1,1 \n",
    "filter_135 = tf.constant(np_filter_135, tf.float32)\n",
    "\t\n",
    "np_filter_sure = np.ones([3,3,1,1]); np_filter_sure[1,1,0,0] = 0\n",
    "filter_sure = tf.constant(np_filter_sure, tf.float32)\n",
    "border_paddings = tf.constant([[0,0],[1,1],[1,1],[0,0]])\n",
    "\n",
    "def Border_Padding(x, pad_width):\n",
    "\tfor _ in range(pad_width): x = tf.pad(x, border_paddings, 'SYMMETRIC')\n",
    "\treturn x\n",
    "\n",
    "def FourAngles(d):\n",
    "\td0   = tf.to_float(tf.greater_equal(d,157.5))+tf.to_float(tf.less(d,22.5))\n",
    "\td45  = tf.to_float(tf.greater_equal(d,22.5))*tf.to_float(tf.less(d,67.5))\n",
    "\td90  = tf.to_float(tf.greater_equal(d,67.5))*tf.to_float(tf.less(d,112.5))\n",
    "\td135 = tf.to_float(tf.greater_equal(d,112.5))*tf.to_float(tf.less(d,157.5))\n",
    "\treturn (d0,d45,d90,d135)\n",
    "\n",
    "\n",
    "def TF_Canny(img_tensor, minRate=0.10, maxRate=0.40,preserve_size=True, remove_high_val=False, return_raw_edges=False):\n",
    "\timg_tensor = (img_tensor)*MAX\n",
    "\tif preserve_size: img_tensor = Border_Padding(img_tensor, (GAUS_KERNEL-1)//2)\n",
    "\n",
    "\tx_gaussian = tf.nn.convolution(img_tensor, gaussian_filter, padding='VALID')\n",
    "\tif remove_high_val: x_gaussian = tf.clip_by_value(x_gaussian, 0, MAX/2)\n",
    "\t\n",
    "\n",
    "\tif preserve_size: x_gaussian = Border_Padding(x_gaussian, 1)\n",
    "\tGx = tf.nn.convolution(x_gaussian, h_filter, padding='VALID')\n",
    "\tGy = tf.nn.convolution(x_gaussian, v_filter, padding='VALID')\n",
    "\tG \t\t= tf.sqrt(tf.square(Gx) + tf.square(Gy))\n",
    "\tBIG_PHI = tf.atan2(Gy,Gx)\n",
    "\tBIG_PHI\t= (BIG_PHI*180/np.pi)%180 \t\t\n",
    "\tD_0,D_45,D_90,D_135 = FourAngles(BIG_PHI)\t\n",
    "\t\n",
    "\t\n",
    "\ttargetPixels_0 = tf.nn.convolution(G, filter_0, padding='SAME')\n",
    "\tisGreater_0 = tf.to_float(tf.greater(G*D_0, targetPixels_0))\n",
    "\tisMax_0 = isGreater_0[:,:,:,0:1]*isGreater_0[:,:,:,1:2]\n",
    "\n",
    "\ttargetPixels_90 = tf.nn.convolution(G, filter_90, padding='SAME')\n",
    "\tisGreater_90 = tf.to_float(tf.greater(G*D_90, targetPixels_90))\n",
    "\tisMax_90 = isGreater_90[:,:,:,0:1]*isGreater_90[:,:,:,1:2]\n",
    "\t\n",
    "\ttargetPixels_45 = tf.nn.convolution(G, filter_45, padding='SAME')\n",
    "\tisGreater_45 = tf.to_float(tf.greater(G*D_45, targetPixels_45))\n",
    "\tisMax_45 = isGreater_45[:,:,:,0:1]*isGreater_45[:,:,:,1:2]\n",
    "\t\n",
    "\ttargetPixels_135 = tf.nn.convolution(G, filter_135, padding='SAME')\n",
    "\tisGreater_135 = tf.to_float(tf.greater(G*D_135, targetPixels_135))\n",
    "\tisMax_135 = isGreater_135[:,:,:,0:1]*isGreater_135[:,:,:,1:2]\n",
    "\n",
    "\tedges_raw = G*(isMax_0 + isMax_90 + isMax_45 + isMax_135)\n",
    "\tedges_raw = tf.clip_by_value(edges_raw, 0, MAX)\n",
    "  \n",
    "\tif return_raw_edges: return tf.squeeze(edges_raw)\n",
    "\t\n",
    "\tedges_sure = tf.to_float(tf.greater_equal(edges_raw, maxRate))\n",
    "\tedges_weak = tf.to_float(tf.less(edges_raw, maxRate))*tf.to_float(tf.greater_equal(edges_raw, minRate))\n",
    "\t\n",
    "\tedges_connected = tf.nn.convolution(edges_sure, filter_sure, padding='SAME')*edges_weak\n",
    "\tfor _ in range(10): edges_connected = tf.nn.convolution(edges_connected, filter_sure, padding='SAME')*edges_weak\n",
    "\t\n",
    "\tedges_final = edges_sure + tf.clip_by_value(edges_connected,0,MAX)\n",
    "\treturn tf.squeeze(edges_final)\n",
    "\n",
    "def edge_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true,dtype = tf.float32)\n",
    "    y_pred = tf.cast(y_pred,dtype = tf.float32)\n",
    "    E = TF_Canny(y_true, return_raw_edges=False)\n",
    "    E = 1 - E\n",
    "    E = tf.cast(E,dtype = tf.float32)\n",
    "    K.print_tensor(E)\n",
    "    A = y_true - y_pred\n",
    "    A = tf.cast(A,dtype = tf.float32)\n",
    "    E = tf.reshape(E,(10,256,256,1))\n",
    "    K.print_tensor(E)\n",
    "    LP = K.abs(A)\n",
    "    LP = tf.cast(LP,dtype = tf.float32)\n",
    "    SQ = K.mean(K.square(y_pred - y_true), axis=-1)\n",
    "    \n",
    "    LE = tf.multiply(E,LP)\n",
    "    LE = tf.cast(LE,dtype = tf.float32)\n",
    "    \n",
    "    SQ1 = K.mean(K.square(LE), axis=-1)\n",
    "    \n",
    "    los = 0.7 * SQ + 0.3 * SQ1\n",
    "    return los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "\n",
    "def compact(x_in):\n",
    "    conv1 = Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same')(x_in)\n",
    "    conv2 = Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same')(conv1)\n",
    "    last = Conv2D(1, strides = 2, kernel_size=(3,3), activation='sigmoid', padding = 'same')(conv2)\n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBF2aDd3vrx6"
   },
   "outputs": [],
   "source": [
    "def compressThis(x_input, quality_factor):\n",
    "    \n",
    "    num = x_input.shape[0]\n",
    "    ans = []\n",
    "    for i in range(num):\n",
    "        x_single = x_input[i,:,:,0]\n",
    "        img = Image.fromarray(np.uint8(x_single*255))\n",
    "        img.save(os.getcwd()+'/com.JPEG',\"JPEG\", quality = quality_factor)\n",
    "        out_single = mpimg.imread(os.getcwd()+'/com.JPEG')\n",
    "        ans.append(out_single)\n",
    "    ans = np.array(ans)\n",
    "    ans = np.reshape(ans, (ans.shape[0], ans.shape[1], ans.shape[2], 1))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3axiTXQGvryD"
   },
   "outputs": [],
   "source": [
    "def load_images(dset_location):\n",
    "    loc = dset_location\n",
    "    images_location = []\n",
    "    X = []\n",
    "\n",
    "    print(\"Extracting image locations..\")\n",
    "    for i in tqdm(os.listdir(loc)):\n",
    "        images_location.append(loc+'/'+i)\n",
    "\n",
    "    print(\"Extracting images..\")\n",
    "    images_location = images_location[:images_count]\n",
    "    for im_loc in tqdm(images_location):\n",
    "        img = cv2.imread(im_loc)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        X.append(img)\n",
    "    X = np.array(X)\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2], 1))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J22TXHq7vryG"
   },
   "outputs": [],
   "source": [
    "def split_dataset(X, split_ratio):\n",
    "    split = int(split_ratio * X.shape[0])\n",
    "    x_train = X[:split,:,:,:]\n",
    "    x_valid = X[split:,:,:,:]\n",
    "    return x_train, x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d8gC-hHKvryJ"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def run():\n",
    "    \n",
    "    X = load_images(dset_location)\n",
    "    x_train, x_valid = split_dataset(X, split_ratio)\n",
    "    \n",
    "    print(\"train images shape : \" + str(x_train.shape))\n",
    "    print(\"valid images shape : \" + str(x_valid.shape))\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    x_train = x_train / 255\n",
    "    x_valid = x_valid / 255\n",
    "\n",
    "    \n",
    "    inp = Input(shape=(None, None, 1))\n",
    "    model_edsr = edsr.edsr(x_in=inp, scale=2)\n",
    "    adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.00000001, decay=0.0, amsgrad=False)\n",
    "    model_edsr.compile(optimizer=adam, loss='mae')\n",
    "    checkpointr = ModelCheckpoint(filepath='edsr.weights.best.hdf5', save_best_only=True, verbose=1)\n",
    "    model_edsr.summary()\n",
    "\n",
    "    \n",
    "    inp = Input(shape=(None, None, 1))\n",
    "    model_comcnn = Model(inp, model_edsr(compact(inp)))\n",
    "    model_comcnn.layers[4].trainable = False\n",
    "    model_comcnn.compile(optimizer='adam', loss=edge_loss)\n",
    "    checkpointc = ModelCheckpoint(filepath='comcnn.weights.best.hdf5', save_best_only=True, verbose=1)\n",
    "    model_comcnn.summary()\n",
    "\n",
    "    \n",
    "    print(\"Entered into final training phase..\")\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        print('Epoch : ' + str(i+1))\n",
    "        \n",
    "        upto_comcnn = Model(model_comcnn.input, model_comcnn.layers[3].output)\n",
    "        xm = upto_comcnn.predict(x_train)\n",
    "        xm_valid = upto_comcnn.predict(x_valid)\n",
    "        \n",
    "        xm_compress = compressThis(xm, QF)\n",
    "        xm_valid_compress = compressThis(xm_valid, QF)\n",
    "        xm_compress = xm_compress.astype('float32')\n",
    "        xm_valid_compress = xm_valid_compress.astype('float32')\n",
    "        xm_compress = xm_compress / 255\n",
    "        xm_valid_compress = xm_valid_compress / 255\n",
    "        \n",
    "        print('Training edsr...')\n",
    "        model_edsr.fit(x=xm_compress, y=x_train, validation_data=(xm_valid_compress, x_valid),epochs=num_of_epochs, shuffle=True, verbose=1, batch_size=8, callbacks=[checkpointr])\n",
    "        print('Training comcnn...')\n",
    "        model_comcnn.fit(x=x_train, y=x_train, validation_data=(x_valid, x_valid),epochs=num_of_epochs, shuffle=True, verbose=1, batch_size=10, callbacks=[checkpointc])\n",
    "        \n",
    "        sample_in = xm_compress[:1]\n",
    "        sample_op = model_edsr.predict(sample_in)\n",
    "        \n",
    "        sample_in = x_train[:1]\n",
    "        sample_op = model_comcnn.predict(sample_in)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ibm9hIeWvryM"
   },
   "outputs": [],
   "source": [
    "dset_location ='/home/titanxpascal/Documents/sem6proj_preetham/img-compression/Subset16k/Subset16k'\n",
    "images_count = 400\n",
    "split_ratio = 0.8\n",
    "QF = 10\n",
    "\n",
    "\n",
    "# ----- final training phase ----------\n",
    "iterations = 500\n",
    "num_of_epochs = 5\n",
    "\n",
    "lr_dim = 128\n",
    "hr_dim = 256\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "end_to_end_compression.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
