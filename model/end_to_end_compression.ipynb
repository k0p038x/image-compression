{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import import_ipynb\n",
    "from tqdm import tqdm as tqdm\n",
    "from original_reccnn import RecCNN\n",
    "from comcnn import ComCNN\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from skimage.measure import compare_ssim as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressThis(x_input, quality_factor):\n",
    "    \n",
    "    # x_input dimension (num, x, y, c)\n",
    "    num = x_input.shape[0]\n",
    "    ans = []\n",
    "    for i in range(num):\n",
    "        x_single = x_input[i]\n",
    "        mpimg.imsave(os.getcwd()+'/org.JPEG', x_single)\n",
    "        tmp = Image.open(os.getcwd()+'/org.JPEG')\n",
    "        tmp.save(os.getcwd()+'/com.JPEG',\"JPEG\", quality = quality_factor)\n",
    "        out_single = mpimg.imread(os.getcwd()+'/com.JPEG')\n",
    "        ans.append(out_single)\n",
    "        \n",
    "    return np.array(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lr(X, scale):\n",
    "    lr = []\n",
    "    for i in tqdm(range(X.shape[0])):\n",
    "        img = X[i]\n",
    "        img = cv2.resize(img, (X.shape[1]/scale , X.shape[2]/scale))\n",
    "        lr.append(img)\n",
    "    return np.array(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(dset_location):\n",
    "    loc = dset_location\n",
    "    images_location = []\n",
    "    X = []\n",
    "\n",
    "    print(\"Extracting image locations..\")\n",
    "    for i in tqdm(os.listdir(loc)):\n",
    "        images_location.append(loc+'/'+i)\n",
    "\n",
    "    print(\"Extracting images..\")\n",
    "    images_location = images_location[:images_count]\n",
    "    for im_loc in tqdm(images_location):\n",
    "        img = cv2.imread(im_loc)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        X.append(img)\n",
    "\n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(X, split_ratio):\n",
    "    split = int(split_ratio * X.shape[0])\n",
    "    x_train = X[:split,:,:,:]\n",
    "    x_valid = X[split:,:,:,:]\n",
    "    return x_train, x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "\n",
    "def run():\n",
    "    \n",
    "    # ----- data loading and pre-processing -------------\n",
    "    X = load_images(dset_location)\n",
    "    x_train, x_valid = split_dataset(X, split_ratio)\n",
    "\n",
    "    print(\"train images shape : \" + str(x_train.shape))\n",
    "    print(\"valid images shape : \" + str(x_valid.shape))\n",
    "\n",
    "    print(\"Generating LR images of train images..\")\n",
    "    x_train_lr = extract_lr(x_train, scale)\n",
    "    print(\"Generating LR images of valid images..\")\n",
    "    x_valid_lr = extract_lr(x_valid, scale)\n",
    "\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    x_train_lr = x_train_lr.astype('float32')\n",
    "    x_valid_lr = x_valid_lr.astype('float32')\n",
    "\n",
    "    x_train = x_train / 255\n",
    "    x_valid = x_valid / 255\n",
    "    x_train_lr = x_train_lr / 255\n",
    "    x_valid_lr = x_valid_lr / 255\n",
    "\n",
    "    print(\"train LR images shape : \" + str(x_train_lr.shape))\n",
    "    print(\"valid LR images shape : \" + str(x_valid_lr.shape))\n",
    "    mpimg.imsave('sample_lr.png', x_train_lr[1])\n",
    "    mpimg.imsave('sample_hr.png', x_train[1])\n",
    "    \n",
    "    #-------- rec-cnn and initial training ----------------\n",
    "    inp = Input(shape=(lr_dim, lr_dim, channels))\n",
    "    rec_cnn = RecCNN(c=channels)\n",
    "    out = rec_cnn.model(filters=filters, scale=scale, h=lr_dim, w=lr_dim, inp=inp)\n",
    "    model_reccnn = Model(inp, out)\n",
    "    model_reccnn.compile(optimizer='adam', loss=reccnn_loss_fun, metrics=['accuracy'])\n",
    "    checkpointr = ModelCheckpoint(filepath='reccnn.weights.best.hdf5', save_best_only=True, verbose=1)\n",
    "    model_reccnn.summary()\n",
    "\n",
    "    if perform_initial_training == True:\n",
    "\n",
    "        print('Entered into reccnn-initial training phase..')\n",
    "        model_reccnn.fit(x=x_train_lr, y=x_train, validation_data=(x_valid_lr, x_valid), epochs=initial_reccnn_epochs, shuffle=True, verbose=1, batch_size=8, callbacks=[checkpointr])\n",
    "\n",
    "        sample_valid_lr = x_valid_lr[:5]\n",
    "        sample_valid = model_reccnn.predict(sample_valid_lr)\n",
    "        mpimg.imsave('initial_reccnn_input.png', sample_valid_lr[1])\n",
    "        mpimg.imsave('initial_reccnn_output.png', sample_valid[1])\n",
    "    \n",
    "    \n",
    "    #---------com-cnn and initial training -------------\n",
    "    inp = Input(shape=(hr_dim, hr_dim, channels))\n",
    "    com_cnn = ComCNN(c=channels)\n",
    "    model_comcnn = Model(inp, model_reccnn(com_cnn.compact(inp)))\n",
    "    model_comcnn.layers[4].trainable = False\n",
    "    model_comcnn.compile(optimizer='adam', loss=comcnn_loss_fun, metrics=['accuracy'])\n",
    "    checkpointc = ModelCheckpoint(filepath='comcnn.weights.best.hdf5', save_best_only=True, verbose=1)\n",
    "    model_comcnn.summary()\n",
    "\n",
    "    if perform_initial_training == True:\n",
    "        print('Entered into comcnn-initial training phase..')\n",
    "        model_comcnn.fit(x=x_train, y=x_train, validation_data=(x_valid, x_valid), epochs=initial_comcnn_epochs, shuffle=True, verbose=1, batch_size=8, callbacks=[checkpointc])\n",
    "\n",
    "        sample_valid_hr = x_valid[:5]\n",
    "        sample_valid = model_comcnn.predict(sample_valid_hr)\n",
    "        mpimg.imsave('initial_hr.png', sample_valid_hr[1])\n",
    "        mpimg.imsave('after_intial_comcnn_hr.png', sample_valid[1])\n",
    "    \n",
    "    #------- end-to-end training ----------\n",
    "    print(\"Entered into final training phase..\")\n",
    "    for i in tqdm(range(iterations)):\n",
    "        # calculating xm using comcnn\n",
    "        upto_comcnn = Model(model_comcnn.input, model_comcnn.layers[3].output)\n",
    "        xm = upto_comcnn.predict(x_train)\n",
    "        xm_valid = upto_comcnn.predict(x_valid)\n",
    "        mpimg.imsave('final-phase/'+str(i)+'-xm.png', xm[0])\n",
    "        xm = compressThis(xm, QF)\n",
    "        xm_valid = compressThis(xm_valid, QF)\n",
    "        xm = xm.astype('float32')\n",
    "        xm_valid = xm_valid.astype('float32')\n",
    "        xm = xm / 255\n",
    "        xm_valid = xm_valid / 255\n",
    "        mpimg.imsave('final-phase/'+str(i)+'-xm_compress.png', xm[0])\n",
    "\n",
    "        # final training phase \n",
    "        model_reccnn.fit(x=xm, y=x_train, validation_data=(xm_valid, x_valid),epochs=num_of_epochs, shuffle=True, verbose=1, batch_size=8, callbacks=[checkpointr])\n",
    "        model_comcnn.fit(x=x_train, y=x_train, validation_data=(x_valid, x_valid),epochs=num_of_epochs, shuffle=True, verbose=1, batch_size=8, callbacks=[checkpointc])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_location = '/home/titanxpascal/Documents/sem6proj/img-compression/Subset16k/Subset16k'\n",
    "images_count = 2500\n",
    "split_ratio = 0.8\n",
    "QF = 10\n",
    "\n",
    "# ----- initial training phase ---------\n",
    "perform_initial_training = True\n",
    "initial_reccnn_epochs = 5\n",
    "initial_comcnn_epochs = 5\n",
    "\n",
    "# ----- final training phase ----------\n",
    "iterations = 50\n",
    "num_of_epochs = 2\n",
    "\n",
    "# ----- rec-cnn parameters -----------\n",
    "filters = 64\n",
    "channels = 3\n",
    "scale = 4\n",
    "lr_dim = 64\n",
    "reccnn_loss_fun = 'mean_squared_error'\n",
    "\n",
    "# ----- com-cnn parameters -----------\n",
    "hr_dim = 256\n",
    "channels = 3\n",
    "comcnn_loss_fun = 'mean_squared_error'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
